{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c033280",
   "metadata": {},
   "source": [
    "# Naive Bayes' Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb437ff",
   "metadata": {},
   "source": [
    "## Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cfe41",
   "metadata": {},
   "source": [
    "This theorem is used to find the probability of an event occuring given the probability that other event has already occured.\n",
    "\n",
    "$$\n",
    "p(A|B) = \\frac {p(A) \\cdot p(B|A)}{p(B)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $p(A)$ is the probability of event $A$ occuring\n",
    "- $p(B)$ is the probability of event $B$ occuring\n",
    "- $p(B|A)$ is the probability that event $B$ occurs given that event $A$ already occured\n",
    "- $p(A|B)$ is the probability that event $A$ occurs given that event $B$ already occured\n",
    "\n",
    "In terms of data science, we find $p(y|X)$ where $y$ is a class variable and $X$ is a dependent feature vector of size $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87626fee",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede01c0c",
   "metadata": {},
   "source": [
    "- The Naive Bayes Classifier is a simple probabilistic classifier and it has very few number of parameters which are used to build the ML models that can predict at a faster speed than other classification algorithms.\n",
    "- It is a probabilistic classifier because it assumes that one feature in the model is independent of existence of another feature. In other words, each feature contributes to the predictions with no relation between each other.\n",
    "- Naive Bayes Algorithm is used in spam filtration, Sentimental analysis, classifying articles and many more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250ff90",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb3694",
   "metadata": {},
   "source": [
    "It is named \"naive\" because it assumes one feature's presence does not affect the other features.\n",
    "<br>\n",
    "\n",
    "- **Feature independence**: This means that when we are trying to classify something, we assume that each feature (or piece of information) in the data does not affect any other feature.\n",
    "- **Continuous features are normally distributed**: If a feature is continuous, then it is assumed to be normally distributed within each class.\n",
    "- **Discrete features have multinomial distributions**: If a feature is discrete, then it is assumed to have a multinomial distribution within each class.\n",
    "- **Features are equally important**: All features are assumed to contribute equally to the prediction of the class label.\n",
    "- **No missing data**: The data should not contain any missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1aaaf",
   "metadata": {},
   "source": [
    "Here is an example with a small dataset of temperature and humidity. We want to predict whether someone should play outdoor activities based on weather conditions.\n",
    "\n",
    "The code demonstrates the following steps:\n",
    "\n",
    "1. **Create a training dataset**: We have 4 samples with features [temperature, humidity] and corresponding labels (1 = Play, 0 = Don't Play)\n",
    "2. **Initialize and train the model**: Using `GaussianNB()`, we fit the classifier to learn the relationship between weather conditions and the decision to play\n",
    "3. **Make a prediction**: For a new day with temperature 28°C and humidity 75%, the model predicts whether to play or not\n",
    "\n",
    "This is a practical example of Naive Bayes classification where the algorithm uses the conditional probability of features (temperature and humidity) given each class to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17098562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for new day: Play\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# [temperature, humidity]\n",
    "X = np.array([\n",
    "    [30, 80],   # Hot and humid\n",
    "    [25, 60],   # Warm and mild\n",
    "    [20, 70],   # Cool and humid\n",
    "    [15, 65],   # Cool and mild\n",
    "])\n",
    "\n",
    "# Labels: 1 = Play, 0 = Don’t Play\n",
    "y = np.array([0, 1, 1, 1])\n",
    "\n",
    "# Create and train the model\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict for a new day\n",
    "new_day = np.array([[28, 75]])  # Hot and humid\n",
    "prediction = clf.predict(new_day)\n",
    "\n",
    "print(\"Prediction for new day:\", \"Play\" if prediction[0] == 1 else \"Don’t Play\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
